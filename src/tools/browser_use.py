"""
KaFlow-Py Browser Use å·¥å…·

å°† browser-use å¼€æºåº“å°è£…æˆ LangChain toolï¼Œæ”¯æŒæµè§ˆå™¨è‡ªåŠ¨åŒ–ä»»åŠ¡

Author: DevYK
å¾®ä¿¡å…¬ä¼—å·: DevYK
Email: yang1001yk@gmail.com
Github: https://github.com/yangkun19921001

Reference: https://github.com/co-browser/browser-use-mcp-server
"""

import asyncio
from typing import Optional, Dict, Any
from langchain_core.tools import tool
from ..utils.logger import get_logger
from ..llms.config import LLMProviderType

logger = get_logger("BrowserUseTool")


def _extract_llm_config(llm: Any) -> Dict[str, Any]:
    """
    ä» LangChain LLM å¯¹è±¡ä¸­æå–é…ç½®ä¿¡æ¯
    
    Args:
        llm: LangChain LLM å®ä¾‹
        
    Returns:
        åŒ…å« api_key, base_url, model, temperature, provider çš„å­—å…¸
    """
    logger.info(f"ğŸ“‹ Extracting config from LLM type: {type(llm).__name__}")
    
    config = {}
    
    # æå– API key (æ”¯æŒä¸åŒçš„å±æ€§å)
    api_key = (
        getattr(llm, "openai_api_key", None) or 
        getattr(llm, "anthropic_api_key", None) or 
        getattr(llm, "google_api_key", None) or 
        getattr(llm, "api_key", None)
    )
    
    # æå– base_url
    base_url = (
        getattr(llm, "openai_api_base", None) or 
        getattr(llm, "base_url", None)
    )
    
    # æå– model
    model = (
        getattr(llm, "model_name", None) or 
        getattr(llm, "model", None)
    )
    
    # æå– temperature
    temperature = getattr(llm, "temperature", 0.0)
    
    # å¤„ç† SecretStr ç±»å‹
    api_key_raw = api_key
    base_url_raw = base_url
    
    if api_key and hasattr(api_key, "get_secret_value"):
        api_key = api_key.get_secret_value()
        logger.debug(f"   âœ“ Decoded SecretStr for api_key")
    
    if base_url and hasattr(base_url, "get_secret_value"):
        base_url = base_url.get_secret_value()
        logger.debug(f"   âœ“ Decoded SecretStr for base_url")
    
    # æ‰“å°åŸå§‹æå–çš„å€¼ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    logger.info(f"   Raw extracted values:")
    logger.info(f"   - api_key type: {type(api_key_raw)}, has value: {bool(api_key)}, length: {len(api_key) if api_key else 0}")
    logger.info(f"   - base_url type: {type(base_url_raw)}, value: {base_url}")
    logger.info(f"   - model: {model}")
    logger.info(f"   - temperature: {temperature}")
    
    # æ³¨æ„ï¼šä¸å†è£å‰ªæ¨¡å‹åç§°ï¼
    # æŸäº› API ä»£ç†ï¼ˆå¦‚ ppinfraï¼‰éœ€è¦å®Œæ•´çš„æ¨¡å‹åç§°ï¼ˆåŒ…æ‹¬å‰ç¼€ï¼‰
    # ä¾‹å¦‚ï¼šdeepseek/deepseek-v3-0324 è€Œä¸æ˜¯ deepseek-v3-0324
    logger.info(f"   â„¹ï¸  Keeping full model name (no trimming): {model}")
    
    config = {
        "api_key": api_key,
        "base_url": base_url,
        "model": model,
        "temperature": temperature,
    }
    
    logger.info(f"   âœ… Final config: model={model}, base_url={base_url}, api_key={'***' + api_key[-4:] if api_key and len(api_key) > 4 else 'None'}")
    
    return config


def _detect_provider_type(llm: Any, config: Dict[str, Any]) -> LLMProviderType:
    """
    æ£€æµ‹ LLM çš„æä¾›å•†ç±»å‹
    
    ä¼˜å…ˆçº§ï¼š
    1. æ£€æŸ¥ LLM å¯¹è±¡çš„ _llm_config å±æ€§ï¼ˆæˆ‘ä»¬è‡ªå·±åˆ›å»ºçš„ LLM ä¼šæœ‰ï¼‰
    2. æ ¹æ®æ¨¡å‹åç§°æ¨æ–­
    3. æ ¹æ® base_url æ¨æ–­
    4. æ ¹æ® LangChain ç±»å‹æ¨æ–­
    
    Args:
        llm: LangChain LLM å®ä¾‹
        config: æå–çš„é…ç½®å­—å…¸
        
    Returns:
        LLMProviderType æšä¸¾å€¼
    """
    # 1. æ£€æŸ¥æ˜¯å¦æœ‰æˆ‘ä»¬å­˜å‚¨çš„åŸå§‹é…ç½®
    if hasattr(llm, "_llm_config"):
        llm_config = getattr(llm, "_llm_config")
        if hasattr(llm_config, "provider"):
            provider = llm_config.provider
            logger.debug(f"âœ… Provider detected from _llm_config: {provider}")
            return provider
    
    # 2. æ ¹æ®æ¨¡å‹åç§°æ¨æ–­
    model = config.get("model", "").lower()
    if "deepseek" in model:
        logger.debug(f"âœ… Provider detected from model name: deepseek")
        return LLMProviderType.DEEPSEEK
    elif "claude" in model:
        logger.debug(f"âœ… Provider detected from model name: claude")
        return LLMProviderType.CLAUDE
    elif "gpt" in model or "o1" in model:
        logger.debug(f"âœ… Provider detected from model name: openai")
        return LLMProviderType.OPENAI
    
    # 3. æ ¹æ® base_url æ¨æ–­
    base_url = config.get("base_url", "")
    if base_url:
        base_url_lower = base_url.lower()
        if "deepseek" in base_url_lower:
            logger.debug(f"âœ… Provider detected from base_url: deepseek")
            return LLMProviderType.DEEPSEEK
        elif "anthropic" in base_url_lower:
            logger.debug(f"âœ… Provider detected from base_url: claude")
            return LLMProviderType.CLAUDE
        elif "openai" in base_url_lower or "azure" in base_url_lower:
            logger.debug(f"âœ… Provider detected from base_url: openai")
            return LLMProviderType.OPENAI
    
    # 4. æ ¹æ® LangChain ç±»å‹æ¨æ–­
    llm_type = type(llm).__name__
    if "Anthropic" in llm_type or "Claude" in llm_type:
        logger.debug(f"âœ… Provider detected from class name: claude")
        return LLMProviderType.CLAUDE
    elif "Azure" in llm_type:
        logger.debug(f"âœ… Provider detected from class name: azure_openai")
        return LLMProviderType.AZURE_OPENAI
    elif "OpenAI" in llm_type:
        logger.debug(f"âœ… Provider detected from class name: openai")
        return LLMProviderType.OPENAI
    
    # é»˜è®¤ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
    logger.warning(f"âš ï¸  Could not detect provider, defaulting to OpenAI-compatible")
    return LLMProviderType.OPENAI


def _create_browser_use_llm(llm: Any):
    """
    æ ¹æ® LangChain LLM åˆ›å»º browser-use çš„ LLM wrapper
    
    browser-use æœ‰è‡ªå·±çš„ LLM wrapperï¼Œéœ€è¦æ ¹æ® provider ç±»å‹è½¬æ¢ã€‚
    
    Args:
        llm: LangChain LLM å®ä¾‹
        
    Returns:
        browser-use å…¼å®¹çš„ LLM å®ä¾‹
    """
    # 1. æå–é…ç½®
    config = _extract_llm_config(llm)
    
    # 2. æ£€æµ‹æä¾›å•†ç±»å‹
    provider = _detect_provider_type(llm, config)
    
    logger.info(f"ğŸ”„ Converting LangChain LLM to browser-use LLM")
    logger.info(f"   Provider: {provider.value}")
    logger.info(f"   Model: {config.get('model')}")
    logger.debug(f"   Base URL: {config.get('base_url')}")
    logger.debug(f"   API Key: {config.get('api_key')[:10] if config.get('api_key') else 'None'}...")
    
    try:
        # 3. æ ¹æ® provider ç±»å‹åˆ›å»ºå¯¹åº”çš„ browser-use LLM
        if provider == LLMProviderType.DEEPSEEK:
            # DeepSeek: ä½¿ç”¨ browser_use.llm.deepseek.chat.ChatDeepSeek
            try:
                from browser_use.llm.deepseek.chat import ChatDeepSeek as BrowserChatDeepSeek
            except ImportError:
                # å¦‚æœä¸Šé¢çš„å¯¼å…¥å¤±è´¥ï¼Œå°è¯•æ—§ç‰ˆæœ¬çš„å¯¼å…¥æ–¹å¼
                logger.warning("âš ï¸  Could not import ChatDeepSeek from browser_use.llm.deepseek.chat, trying OpenAI-compatible interface")
                from browser_use import ChatOpenAI as BrowserChatOpenAI
                fallback_base_url = config.get("base_url") or "https://api.deepseek.com/v1"
                logger.info(f"   Fallback to ChatOpenAI with:")
                logger.info(f"   - model: {config['model']}")
                logger.info(f"   - base_url: {fallback_base_url}")
                logger.info(f"   - api_key: ***{config['api_key'][-4:] if config.get('api_key') else 'None'}")
                return BrowserChatOpenAI(
                    model=config["model"],
                    api_key=config["api_key"],
                    base_url=fallback_base_url,
                    temperature=config.get("temperature", 0.0),
                )
            
            # æ„å»º DeepSeek å‚æ•°
            deepseek_kwargs = {
                "model": config["model"],
                "api_key": config["api_key"],
                "temperature": config.get("temperature", 0.0),
            }
            
            # æ·»åŠ  base_urlï¼ˆå¦‚æœæä¾›äº†ï¼‰
            if config.get("base_url"):
                deepseek_kwargs["base_url"] = config["base_url"]
                logger.info(f"   ğŸ“ Using custom base_url: {config['base_url']}")
            else:
                logger.info(f"   ğŸ“ Using default DeepSeek base_url (not set, will use ChatDeepSeek default)")
            
            logger.info(f"âœ… Creating browser-use ChatDeepSeek with parameters:")
            logger.info(f"   - model: {deepseek_kwargs['model']}")
            logger.info(f"   - base_url: {deepseek_kwargs.get('base_url', 'https://api.deepseek.com/v1 (default)')}")
            logger.info(f"   - api_key: ***{deepseek_kwargs['api_key'][-4:] if deepseek_kwargs.get('api_key') else 'None'}")
            logger.info(f"   - temperature: {deepseek_kwargs['temperature']}")
            
            return BrowserChatDeepSeek(**deepseek_kwargs)
        
        elif provider == LLMProviderType.CLAUDE:
            # Claude: ä½¿ç”¨ browser_use.ChatAnthropic
            from browser_use import ChatAnthropic as BrowserChatAnthropic
            
            logger.info(f"âœ… Creating browser-use ChatAnthropic")
            return BrowserChatAnthropic(
                model=config.get("model", "claude-3-5-sonnet-20241022"),
                api_key=config["api_key"],
            )
        
        elif provider in (LLMProviderType.OPENAI, LLMProviderType.AZURE_OPENAI, LLMProviderType.CUSTOM):
            # OpenAI / Azure / Custom: ä½¿ç”¨ browser_use.ChatOpenAI
            from browser_use import ChatOpenAI as BrowserChatOpenAI
            
            openai_kwargs = {
                "model": config.get("model", "gpt-4"),
                "api_key": config["api_key"],
                "temperature": config.get("temperature", 0.0),
            }
            
            # æ·»åŠ  base_urlï¼ˆå¦‚æœæœ‰ï¼‰
            if config.get("base_url"):
                openai_kwargs["base_url"] = config["base_url"]
            
            logger.info(f"âœ… Creating browser-use ChatOpenAI")
            return BrowserChatOpenAI(**openai_kwargs)
        
        else:
            # å…¶ä»–ç±»å‹ï¼šå°è¯• OpenAI å…¼å®¹æ¥å£
            logger.warning(f"âš ï¸  Unknown provider {provider}, trying OpenAI-compatible interface")
            from browser_use import ChatOpenAI as BrowserChatOpenAI
            
            return BrowserChatOpenAI(
                model=config.get("model", "gpt-4"),
                api_key=config["api_key"],
                base_url=config.get("base_url"),
                temperature=config.get("temperature", 0.0),
            )
    
    except Exception as e:
        logger.error(f"âŒ Failed to convert LLM: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        raise ValueError(f"Failed to create browser-use LLM for provider {provider.value}: {str(e)}")


def create_browser_use_tool(llm: Any, **browser_config):
    """
    åˆ›å»º browser-use å·¥å…·çš„å·¥å‚å‡½æ•°
    
    Args:
        llm: LangChain LLM å®ä¾‹ï¼ˆå°†è¢«è½¬æ¢ä¸º browser-use çš„ LLM wrapperï¼‰
        **browser_config: æµè§ˆå™¨é…ç½®å‚æ•°
            - headless: bool = False, æ˜¯å¦æ— å¤´æ¨¡å¼
            - disable_security: bool = False, æ˜¯å¦ç¦ç”¨å®‰å…¨ç‰¹æ€§
            - window_w: int = 1280, çª—å£å®½åº¦
            - window_h: int = 1100, çª—å£é«˜åº¦
            - save_recording_path: Optional[str] = None, å½•å±ä¿å­˜è·¯å¾„
    
    Returns:
        LangChain tool å‡½æ•°
        
    Examples:
        >>> from langchain_openai import ChatOpenAI
        >>> llm = ChatOpenAI(model="gpt-4")
        >>> browser_tool = create_browser_use_tool(llm, headless=False)
        >>> result = await browser_tool.ainvoke({"task": "è®¿é—® github.com å¹¶è·å–é¦–é¡µå†…å®¹"})
    """
    
    # è½¬æ¢ LLM ä¸º browser-use çš„ wrapper
    browser_llm = _create_browser_use_llm(llm)
    
    # æµè§ˆå™¨é…ç½®
    config = {
        "headless": browser_config.get("headless", False),
        "disable_security": browser_config.get("disable_security", False),
        "window_w": browser_config.get("window_w", 1280),
        "window_h": browser_config.get("window_h", 1100),
        "save_recording_path": browser_config.get("save_recording_path", None),
    }
    
    @tool
    async def browser_use(task: str) -> str:
        """
        ä½¿ç”¨ AI æ§åˆ¶æµè§ˆå™¨æ‰§è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡
        
        æ­¤å·¥å…·å¯ä»¥ï¼š
        - è®¿é—®ç½‘ç«™å¹¶æå–ä¿¡æ¯
        - å¡«å†™è¡¨å•å’Œæ‰§è¡Œç½‘é¡µæ“ä½œ
        - ç½‘é¡µå¯¼èˆªå’Œæœç´¢
        - æ•°æ®æŠ“å–å’Œä¿¡æ¯æ”¶é›†
        - æˆªå›¾å’Œè®°å½•æ“ä½œè¿‡ç¨‹
        
        Args:
            task: è¦æ‰§è¡Œçš„æµè§ˆå™¨ä»»åŠ¡æè¿°ï¼Œä¾‹å¦‚ï¼š
                - "è®¿é—® github.com/browser-use/browser-useï¼Œè·å–é¡¹ç›®çš„ star æ•°é‡"
                - "åœ¨ Google ä¸Šæœç´¢ 'Python web scraping'ï¼Œè·å–å‰ 3 ä¸ªç»“æœ"
                - "è®¿é—®è‚¡ç¥¨ç½‘ç«™ï¼Œè·å–ç‰¹æ–¯æ‹‰çš„æœ€æ–°è‚¡ä»·"
        
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœçš„æ–‡æœ¬æè¿°
        """
        try:
            from browser_use import Agent, Browser
            
            logger.info(f"ğŸŒ Starting browser task: {task[:100]}...")
            
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹ (Browser åœ¨ 0.7.10 ä¸­å·²ç»åŒ…å«é…ç½®)
            browser = Browser(
                headless=config["headless"],
                disable_security=config["disable_security"],
            )
            
            # åˆ›å»º Agentï¼ˆä½¿ç”¨ browser-use çš„ LLM wrapperï¼‰
            agent = Agent(
                task=task,
                llm=browser_llm,
                browser=browser,
            )
            
            # æ‰§è¡Œä»»åŠ¡
            try:
                result = await agent.run()
            except Exception as e:
                logger.error(f"âŒ browser-use agent.run() failed: {type(e).__name__}: {str(e)}")
                import traceback
                logger.debug(f"Traceback: {traceback.format_exc()}")
                raise
            
            # ä¿å­˜å½•å±ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if config["save_recording_path"]:
                try:
                    history = agent.history()
                    save_path = config["save_recording_path"]
                    logger.info(f"ğŸ’¾ Saving recording to: {save_path}")
                    # è¿™é‡Œå¯ä»¥æ·»åŠ ä¿å­˜é€»è¾‘
                except Exception as e:
                    logger.warning(f"Failed to save recording: {e}")
            
            logger.info(f"âœ… Browser task completed successfully")
            
            # è¿”å›ç»“æœ
            return str(result)
            
        except ImportError as e:
            error_msg = (
                "âŒ browser-use is not installed.\n"
                "Please install it with:\n"
                "  uv pip install browser-use playwright\n"
                "  uvx playwright install chromium --with-deps --no-shell"
            )
            logger.error(error_msg)
            return error_msg
            
        except Exception as e:
            error_msg = f"âŒ Browser task failed: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    # å­˜å‚¨é…ç½®ä¿¡æ¯åˆ° tool çš„å…ƒæ•°æ®
    browser_use._browser_config = config
    browser_use._browser_llm = browser_llm
    browser_use._original_llm = llm
    
    return browser_use


def create_browser_use_with_context_tool(llm: Any, **browser_config):
    """
    åˆ›å»ºå¸¦ä¸Šä¸‹æ–‡çš„ browser-use å·¥å…·ï¼ˆæ”¯æŒå¤šæ­¥éª¤ä»»åŠ¡ï¼‰
    
    è¿™ä¸ªç‰ˆæœ¬æ”¯æŒåœ¨åŒä¸€ä¸ªæµè§ˆå™¨ä¼šè¯ä¸­æ‰§è¡Œå¤šä¸ªæ­¥éª¤ï¼Œä¿æŒé¡µé¢çŠ¶æ€ã€‚
    é€‚åˆéœ€è¦è¿ç»­æ“ä½œçš„åœºæ™¯ï¼Œå¦‚ï¼šç™»å½•ã€å¯¼èˆªã€å¡«è¡¨å•ç­‰ã€‚
    
    Args:
        llm: LangChain LLM å®ä¾‹
        **browser_config: æµè§ˆå™¨é…ç½®å‚æ•°
    
    Returns:
        LangChain tool å‡½æ•°
    """
    
    # è½¬æ¢ LLM ä¸º browser-use çš„ wrapper
    browser_llm = _create_browser_use_llm(llm)
    
    # å…±äº«çš„æµè§ˆå™¨å®ä¾‹
    browser_instance = {"browser": None, "agent": None}
    
    @tool
    async def browser_use_with_context(
        task: str, 
        action: str = "execute"
    ) -> str:
        """
        ä½¿ç”¨ AI æ§åˆ¶æµè§ˆå™¨æ‰§è¡Œä»»åŠ¡ï¼ˆæ”¯æŒä¼šè¯ä¿æŒï¼‰
        
        Args:
            task: è¦æ‰§è¡Œçš„æµè§ˆå™¨ä»»åŠ¡æè¿°
            action: æ“ä½œç±»å‹
                - "execute": æ‰§è¡Œä»»åŠ¡ï¼ˆé»˜è®¤ï¼‰
                - "reset": é‡ç½®æµè§ˆå™¨ä¼šè¯
                - "close": å…³é—­æµè§ˆå™¨
        
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        try:
            from browser_use import Agent, Browser
            
            # å¤„ç†ç‰¹æ®Šæ“ä½œ
            if action == "close":
                if browser_instance["browser"]:
                    # await browser_instance["browser"].close()
                    browser_instance["browser"] = None
                    browser_instance["agent"] = None
                    logger.info("ğŸ”’ Browser closed")
                return "Browser closed successfully"
            
            if action == "reset":
                if browser_instance["browser"]:
                    # await browser_instance["browser"].close()
                    browser_instance["browser"] = None
                    browser_instance["agent"] = None
                logger.info("ğŸ”„ Browser session reset")
                return "Browser session reset successfully"
            
            # åˆ›å»ºæˆ–å¤ç”¨æµè§ˆå™¨å®ä¾‹
            if browser_instance["browser"] is None:
                browser_instance["browser"] = Browser(
                    headless=browser_config.get("headless", False),
                    disable_security=browser_config.get("disable_security", False),
                )
                logger.info("ğŸŒ New browser instance created")
            
            # æ‰§è¡Œä»»åŠ¡
            logger.info(f"â–¶ï¸  Executing task: {task[:100]}...")
            
            agent = Agent(
                task=task,
                llm=browser_llm,
                browser=browser_instance["browser"],
            )
            
            result = await agent.run()
            logger.info(f"âœ… Task completed")
            
            return str(result)
            
        except Exception as e:
            error_msg = f"âŒ Browser task failed: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    return browser_use_with_context


# ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºé»˜è®¤é…ç½®çš„ browser-use å·¥å…·
def get_browser_use_tool(llm: Any, headless: bool = False) -> Any:
    """
    å¿«é€Ÿåˆ›å»ºé»˜è®¤é…ç½®çš„ browser-use å·¥å…·
    
    Args:
        llm: LangChain LLM å®ä¾‹
        headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆé»˜è®¤ Falseï¼Œæ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼‰
    
    Returns:
        browser-use tool
    
    Examples:
        >>> from langchain_openai import ChatOpenAI
        >>> llm = ChatOpenAI(model="gpt-4")
        >>> browser_tool = get_browser_use_tool(llm)
        >>> 
        >>> # åœ¨ Agent ä¸­ä½¿ç”¨
        >>> tools = [browser_tool, other_tool]
        >>> agent = create_react_agent(model=llm, tools=tools)
    """
    return create_browser_use_tool(llm, headless=headless)


# å·¥å…·é…ç½®è¾…åŠ©ç±»
class BrowserUseToolConfig:
    """Browser Use Tool é…ç½®ç±»"""
    
    @staticmethod
    def default() -> Dict[str, Any]:
        """é»˜è®¤é…ç½®"""
        return {
            "headless": False,
            "disable_security": False,
            "window_w": 1280,
            "window_h": 1100,
            "save_recording_path": None,
        }
    
    @staticmethod
    def headless() -> Dict[str, Any]:
        """æ— å¤´æ¨¡å¼é…ç½®ï¼ˆæœåŠ¡å™¨ç¯å¢ƒï¼‰"""
        return {
            "headless": True,
            "disable_security": False,
            "window_w": 1920,
            "window_h": 1080,
            "save_recording_path": None,
        }
    
    @staticmethod
    def debug() -> Dict[str, Any]:
        """è°ƒè¯•æ¨¡å¼é…ç½®ï¼ˆæ…¢é€Ÿã€å¯è§çª—å£ï¼‰"""
        return {
            "headless": False,
            "disable_security": True,
            "window_w": 1280,
            "window_h": 1100,
            "save_recording_path": "./browser_recordings/",
        }


__all__ = [
    "create_browser_use_tool",
    "create_browser_use_with_context_tool",
    "get_browser_use_tool",
    "BrowserUseToolConfig",
] 